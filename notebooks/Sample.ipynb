{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d36d537-9449-423c-a470-f4d1717f7e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pickle   \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5dc813-d22b-4530-bf14-29e0a0331f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Будет использоваться устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "# Определяем устройство для вычислений (CPU или GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Будет использоваться устройство:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe2ae2c-3d52-4dc9-a296-722b53ddefbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Успешно загружены токенизатор и модель Transformers из локальной папки.\n",
      "ℹ️ Пользуемся sklearn/keras/PyTorch state-dict, инференс будет на CPU.\n",
      "\n",
      "== Итоги загрузки модели ==\n",
      "Model object type: <class 'transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification'>\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = '../models/final_model'\n",
    "\n",
    "if not os.path.isdir(MODEL_DIR):\n",
    "    raise FileNotFoundError(f\"Каталог с моделью не найден: {MODEL_DIR}\")\n",
    "\n",
    "# 1) пытаемся загрузить как HF-трансформер\n",
    "model = None\n",
    "tokenizer = None\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, local_files_only=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, local_files_only=True)\n",
    "    print(\"✅ Успешно загружены токенизатор и модель Transformers из локальной папки.\")\n",
    "except Exception as hf_err:\n",
    "    print(\"⚠️ Не удалось загрузить как Transformers-модель:\", hf_err)\n",
    "\n",
    "# 2) если не трансформер — ищем файлы с другими расширениями\n",
    "if model is None:\n",
    "    # список файлов в папке\n",
    "    files = os.listdir(MODEL_DIR)\n",
    "    # ищем PyTorch state-dict (.pt/.pth)\n",
    "    pt_files = [f for f in files if f.endswith(('.pt','.pth'))]\n",
    "    # ищем sklearn pickle/joblib (.pkl/.joblib/.sav)\n",
    "    pkl_files = [f for f in files if f.endswith(('.pkl','.joblib','.sav'))]\n",
    "    # ищем Keras H5 (.h5)\n",
    "    h5_files  = [f for f in files if f.endswith('.h5')]\n",
    "    \n",
    "    if pt_files:\n",
    "        pt_path = os.path.join(MODEL_DIR, pt_files[0])\n",
    "        try:\n",
    "            model = torch.load(pt_path, map_location='cpu')\n",
    "            print(f\"✅ Загружен PyTorch-модель из файла {pt_files[0]} на CPU.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка при загрузке PyTorch-модели {pt_files[0]}:\", e)\n",
    "    elif pkl_files:\n",
    "        pkl_path = os.path.join(MODEL_DIR, pkl_files[0])\n",
    "        try:\n",
    "            model = pickle.load(open(pkl_path, 'rb'))\n",
    "            print(f\"✅ Загружена модель sklearn (pickle) из {pkl_files[0]}.\")\n",
    "        except Exception:\n",
    "            # пробуем joblib.load\n",
    "            try:\n",
    "                model = joblib.load(pkl_path)\n",
    "                print(f\"✅ Загружена модель sklearn (joblib) из {pkl_files[0]}.\")\n",
    "            except Exception as e2:\n",
    "                print(f\"❌ Ошибка при загрузке sklearn-модели из {pkl_files[0]}:\", e2)\n",
    "    elif h5_files:\n",
    "        from tensorflow import keras\n",
    "        h5_path = os.path.join(MODEL_DIR, h5_files[0])\n",
    "        try:\n",
    "            model = keras.models.load_model(h5_path)\n",
    "            print(f\"✅ Загружена Keras-модель из файла {h5_files[0]}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка при загрузке Keras-модели {h5_files[0]}:\", e)\n",
    "    else:\n",
    "        print(\"❌ В папке нет файлов с известными расширениями .pt/.pth/.pkl/.joblib/.h5.\")\n",
    "\n",
    "# 3) если модель загрузилась — размещаем на нужном устройстве\n",
    "if isinstance(model, AutoModelForSequenceClassification):\n",
    "    # определяем устройство\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        try:\n",
    "            torch.cuda.empty_cache()\n",
    "            model.to(device)\n",
    "            print(f\"✅ Трансформер перемещён на {device}.\")\n",
    "        except RuntimeError as oom:\n",
    "            if 'out of memory' in str(oom):\n",
    "                print(\"⚠️ CUDA OOM — оставляем модель на CPU.\")\n",
    "                device = torch.device('cpu')\n",
    "                model.to(device)\n",
    "            else:\n",
    "                raise\n",
    "    else:\n",
    "        print(\"ℹ️ GPU недоступен, используем CPU.\")\n",
    "    model.eval()\n",
    "else:\n",
    "    # для sklearn/keras/PyTorch state-dict устройство управляется в процессе инференса\n",
    "    device = torch.device('cpu')\n",
    "    print(\"ℹ️ Пользуемся sklearn/keras/PyTorch state-dict, инференс будет на CPU.\")\n",
    "\n",
    "# Финальное состояние\n",
    "print(\"\\n== Итоги загрузки модели ==\")\n",
    "print(\"Model object type:\", type(model))\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5078bedd-488f-41e8-a9bf-90a5887a7159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выбрана случайная строка из тестовых данных:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>Спорт</th>\n",
       "      <th>Личная жизнь</th>\n",
       "      <th>Юмор</th>\n",
       "      <th>Соцсети</th>\n",
       "      <th>Политика</th>\n",
       "      <th>Реклама</th>\n",
       "      <th>Нет категории</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>доброе утро☀️ настя веневитина женщина- кошка ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ну что , друзья , впервые мне реально интересн...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>в этот день немного грущу из-за олимпиады. пов...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>пока виктор михайлович возит константина михай...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>замечали, что когда надо встать рано, чтобы, н...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  Спорт  Личная жизнь  \\\n",
       "0  доброе утро☀️ настя веневитина женщина- кошка ...    0.0           0.5   \n",
       "1  ну что , друзья , впервые мне реально интересн...    0.0           0.0   \n",
       "2  в этот день немного грущу из-за олимпиады. пов...    1.0           0.0   \n",
       "3  пока виктор михайлович возит константина михай...    0.5           0.0   \n",
       "4  замечали, что когда надо встать рано, чтобы, н...    0.0           0.0   \n",
       "\n",
       "   Юмор  Соцсети  Политика  Реклама  Нет категории  \n",
       "0   0.0      0.5       0.0      0.0            0.0  \n",
       "1   0.0      0.5       0.5      0.0            0.0  \n",
       "2   0.0      0.0       0.0      0.0            0.0  \n",
       "3   0.0      0.0       0.0      0.5            0.0  \n",
       "4   0.0      0.0       0.0      0.0            1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Пытаемся загрузить тестовые данные из data/processed\n",
    "test_df = None\n",
    "# Проверяем доступность файлов с данными\n",
    "if  os.path.exists('../data/processed/final.xlsx'):\n",
    "    # берем данные из обработанного датасета\n",
    "    full_df = pd.read_excel('../data/processed/final.xlsx')\n",
    "    # Удаляем лишний индекс-столбец, если он есть\n",
    "    if 'Unnamed: 0' in full_df.columns:\n",
    "        full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "    test_df = full_df\n",
    "\n",
    "if test_df is not None and not test_df.empty:\n",
    "    # Выбираем одну случайную строку без фиксации random_state\n",
    "    test_df = test_df.sample(n=5).reset_index(drop=True)\n",
    "    print(\"Выбрана случайная строка из тестовых данных:\")\n",
    "    display(test_df.head())\n",
    "else:\n",
    "    print(\"Тестовые данные не найдены или они пустые, будет сгенерирован пример вручную.\")\n",
    "    # Генерируем пример вручную\n",
    "    test_df = pd.DataFrame({\n",
    "        'full_text': [\n",
    "            \"Президент провёл заседание по вопросам экономической политики.\"\n",
    "        ]\n",
    "    })\n",
    "    display(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb72d43f-c9f7-4e16-a093-d151012da825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) доброе утро☀️ настя веневитина женщина- кошка я еду наверное...\n",
      "2) ну что , друзья , впервые мне реально интересно почитать ваш...\n",
      "3) в этот день немного грущу из-за олимпиады. поверьте, энергет...\n",
      "4) пока виктор михайлович возит константина михайловича…😉  2 из...\n",
      "5) замечали, что когда надо встать рано, чтобы, например, поеха...\n"
     ]
    }
   ],
   "source": [
    "# Подготовка списка текстовых примеров для предсказания\n",
    "text_examples = []\n",
    "true_labels = None  # сюда сохраним истинные метки, если они известны (для демонстрации)\n",
    "\n",
    "if test_df is not None:\n",
    "    # Определяем имя колонки с текстом (предположим, 'full_text')\n",
    "    text_col = 'full_text' if 'full_text' in test_df.columns else test_df.columns[0]\n",
    "    # Получаем тексты (возьмём до 5 примеров для наглядности)\n",
    "    text_examples = test_df[text_col].astype(str).tolist()[:5]\n",
    "    # Если в данных присутствуют столбцы с метками классов (например, многоклассовые бинарные индикаторы)\n",
    "else:\n",
    "    # Генерируем пример текста вручную\n",
    "    text_examples = [\n",
    "        \"Президент провёл заседание по вопросам экономической политики.\",  # ожидание категории \"Политика\"\n",
    "        \"Этот фильм был настолько смешным, что я смеялся весь вечер.\"      # ожидание категории \"Юмор\"\n",
    "    ]\n",
    "    print(\"Примеры текстов для предсказания (сгенерированы вручную).\")\n",
    "    \n",
    "# Выводим сами тексты для проверки\n",
    "for i, text in enumerate(text_examples, 1):\n",
    "    print(f\"{i}) {text[:60]}{'...' if len(text) > 60 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc09b464-7bbf-4b3f-9dda-9bc69f268b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Будем использовать max_length = 512\n",
      "✅ Токенизация выполнена. Ключи в inputs: dict_keys(['input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "# Определяем max_length для токенизации\n",
    "# Если tokenizer.model_max_length задан и разумен — используем его, иначе ставим 512\n",
    "max_len = getattr(tokenizer, 'model_max_length', None)\n",
    "if not isinstance(max_len, int) or max_len > 10000:\n",
    "    max_len = 512\n",
    "print(f\"Будем использовать max_length = {max_len}\")\n",
    "\n",
    "# Токенизация с явным указанием max_length\n",
    "inputs = tokenizer(\n",
    "    text_examples,\n",
    "    padding='max_length',   # паддинг до max_length\n",
    "    truncation=True,        # обрезаем тексты длиннее max_length\n",
    "    max_length=max_len,     # максимальная длина\n",
    "    return_tensors='pt'     # PyTorch-тензоры\n",
    ")\n",
    "\n",
    "# Переносим тензоры на устройство\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "print(\"✅ Токенизация выполнена. Ключи в inputs:\", inputs.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3788bb18-fc20-4f53-a304-303456a13a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания получены. Форма массива вероятностей: (5, 7)\n"
     ]
    }
   ],
   "source": [
    "# Получаем предсказания модели на токенизированных данных\n",
    "with torch.no_grad():  # выключаем вычисление градиентов, т.к. сейчас инференс\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits  # логиты (выходы до применения функции активации) размером [batch_size, num_labels]\n",
    "\n",
    "# Преобразуем логиты в вероятности сигмоидой, т.к. это multi-label классификация\n",
    "probs_tensor = torch.sigmoid(logits)\n",
    "# Переносим на CPU и в numpy для дальнейшей обработки\n",
    "probs = probs_tensor.cpu().numpy()\n",
    "\n",
    "# Определяем предсказанные метки при пороге 0.5\n",
    "pred_labels = (probs >= 0.5).astype(int)\n",
    "\n",
    "print(\"Предсказания получены. Форма массива вероятностей:\", probs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0e44f3-1bf8-4119-be49-7d5273535d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Пример 1. Текст: доброе утро☀️ настя веневитина женщина- кошка я еду наверное тоже вовремя 12 :49 бомжи высмеяли мое платье 12: 52 я наверное не приеду 12 :52\n",
      "Предсказанные категории: Личная жизнь, Соцсети\n",
      "Вероятности (по порядку категорий): Спорт: 0.01, Личная жизнь: 0.99, Юмор: 0.01, Соцсети: 0.95, Политика: 0.01, Реклама: 0.01, Нет категории: 0.01\n",
      "\n",
      "Пример 2. Текст: ну что , друзья , впервые мне реально интересно почитать ваши комментарии)) скажу честно : мне вот по…..уй)))) я даже рад ! я манал всех блогеров , и прочее , а что скажете вы ?))) с 1 марта вступит в силу запрет на популяризацию мна vрn-сервисов сегодня, 18:13 москва, 5 февраля. /тасс| средства обхода блокировок в рф запрещены, с 1 марта вступит в силу запрет на популяризацию таких сервисов. об этом сообщили тасс в роскомнадзоре в ответ на публикации о запрете vрn. 9 w «в соответствии с законодательством в россии запрещена работа средств обхода блокировок доступа к противоправному контенту с февраля 2020 года. vрn-сервисы относятся к таким средствам, если при их использовании не ограничивается доступ к запрещенным ресурсам» ~ говорится в сообщении. как напомнили в ведомстве, с 1 марта 2024\n",
      "Предсказанные категории: Соцсети, Политика\n",
      "Вероятности (по порядку категорий): Спорт: 0.00, Личная жизнь: 0.01, Юмор: 0.01, Соцсети: 0.96, Политика: 0.86, Реклама: 0.01, Нет категории: 0.00\n",
      "\n",
      "Пример 3. Текст: в этот день немного грущу из-за олимпиады. поверьте, энергетически они круче евро и чм. ну, для меня.  вся энергия концентрируется в одном месте, а не рассеяна по городам и даже странам. мультикультурность, разные страны, люди, болелы, разные континенты. про участников-камикадзе, у которых самый главный старт за 4 года, тыщу раз писал. в моём любимом дзюдо главное событие карьеры может продлиться 10 секунд. вышел, проморгал - всё, иппон. и напряжение у людей бешеное: во многих видах героем страны и мировой звездой можешь стать только здесь.  у меня были две олимпиады с места: лондонская и сочинская. в 12-м комментил дзюдо, борьбу, тхэквондо, в 14-м - прыжки на лыжах с трамплина. в лондоне вообще повезло комментировать схватки приятелей, с которыми татами делил. те краски - одни из главных в карьере, пропуск остальных поездок - боль.   поэтому я даже не представляю, какое это профессиональное горе для наших спортсменов - потерять олимпиады. инал тасоев, например, лишился шанса убрать легендарного тедди ринера у него на родине, в париже! а ведь мог бы.  очень жаль спортсменов. жаль вот такие олимпийские игры. а тем, кто добрался до парижа - удачи. это память на всю жизнь.  @shhhnyakin pvw\n",
      "Предсказанные категории: Спорт\n",
      "Вероятности (по порядку категорий): Спорт: 0.99, Личная жизнь: 0.01, Юмор: 0.00, Соцсети: 0.01, Политика: 0.01, Реклама: 0.01, Нет категории: 0.00\n",
      "\n",
      "Пример 4. Текст: пока виктор михайлович возит константина михайловича…😉  2 из 2 👏👏👏 | winline обе забьютитб 2.5 1.95 цска ф t- 1 .5} з 15 о- 1 гол в матче 270 2* победа зенита и 03 360 динамо не проиграет и 03 2.07 победа оренбурга 218 ничья з 75 с краснодар ф t-1.51 216 гол крыльев в 1-м тайме 1.95 : победа цска 1. 85 первый гол - факел 1.85 2* 2 тайм » 1 тайм 210 динамо не проиграет и 03 2 07 прогнозы 166 обе забьют тур победа спартака 188 рпл а краснодар ф t~1.51 216\n",
      "Предсказанные категории: Спорт\n",
      "Вероятности (по порядку категорий): Спорт: 1.00, Личная жизнь: 0.00, Юмор: 0.01, Соцсети: 0.01, Политика: 0.00, Реклама: 0.02, Нет категории: 0.01\n",
      "\n",
      "Пример 5. Текст: замечали, что когда надо встать рано, чтобы, например, поехать в аэропорт, то и пробуждение не такое тяжелое, как если нужно проснуться, чтобы пойти на работу. вообще, полюбить вставать по утрам - целая наука, давайте-как разберемся, как это сделать.    во-первых, стоит запланировать на утро что-то такое, ради чего захочется встать, например, тренировку ( сейчас лето, можно перед работой позаниматься на улице). даже 15 минут занятий смогут скрасить это утро. а еще можно запланировать приятные бьюти ритуалы на утро, ради которых захочется встать.  найдите общий язык с будильником, настроив свои биологические часы так, чтобы ложиться и засыпать в одно и тоже время.  а еще отличный способ поставить вместо стандартного будильника любимый трек, тогда и пробуждение не будет таким резким, ведь, захочется подпевать.  а как вы справляетесь к ранними подъемами? 7:00 7: 05 7:10 у 7) до новых встреч!\n",
      "Предсказанные категории: Нет категории\n",
      "Вероятности (по порядку категорий): Спорт: 0.01, Личная жизнь: 0.01, Юмор: 0.01, Соцсети: 0.01, Политика: 0.00, Реклама: 0.01, Нет категории: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Определяем список названий классов/тем для вывода (если не определён из данных)\n",
    "label_cols = ['Спорт', 'Личная жизнь', 'Юмор', 'Соцсети', 'Политика', 'Реклама', 'Нет категории']\n",
    "\n",
    "# Проходим по каждому примеру и выводим информацию\n",
    "for i, text in enumerate(text_examples):\n",
    "    print(f\"\\nПример {i+1}. Текст: {text}\")\n",
    "    # Истинные категории (если известны)\n",
    "    if true_labels is not None:\n",
    "        true_topics = [label_cols[j] for j, val in enumerate(true_labels[i]) if val == 1]\n",
    "        print(\"Истинные категории:\", \", \".join(true_topics) if true_topics else \"нет\")\n",
    "    # Предсказанные категории\n",
    "    pred_topics = [label_cols[j] for j, val in enumerate(pred_labels[i]) if val == 1]\n",
    "    print(\"Предсказанные категории:\", \", \".join(pred_topics) if pred_topics else \"нет\")\n",
    "    # Вероятности по каждой категории\n",
    "    probs_str = \", \".join(f\"{label_cols[j]}: {p:.2f}\" for j, p in enumerate(probs[i]))\n",
    "    print(\"Вероятности (по порядку категорий):\", probs_str)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIFI Hackaton Polyglot News Analyzer (MIFI_Hackaton_Polyglot_News_Analyzer)",
   "language": "python",
   "name": "mifi_hackaton_polyglot_news_analyzer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
